
<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<title> Audio Visualization </title>
</head>
<body>		
	<h1> Mini Project #1: Loudness Mapping </h1>
	
	<input id="fileChooseInput" type="file"></input>
	<button onclick="playSound(myAudioBuffer)">Play</button>
	<button onclick="stopSound()">Stop</button>	  

	<p><canvas id='wave_view' style="background: white;"></canvas></p>

	<script>	
	var context;
	var myAudioBuffer = null;
	var analyser;
	
	var start, current, time;

	var peak=[0];

	var wave_view;
	var WIDTH = 512;
	var HEIGHT = 512;
	
	var amp_envelop;

	//
	window.onload=function(){
		// file open button
		var control = document.getElementById("fileChooseInput");
		control.addEventListener("change", fileChanged, false);
		
		// canvas 
		wave_view = document.getElementById("wave_view");
		wave_view.width =  WIDTH;
		wave_view.height = HEIGHT;
		
		// create audio context
		context = new AudioContext();
		
		// analyzer
	    analyser = context.createAnalyser();
	    analyser.fftSize = 256;
		analyser.smoothingTimeConstant = 0;		
	}
	
	function draw_wave(timestamp) {		
		// 2d canvas context
		var drawContext = wave_view.getContext('2d');
		
		// fill rectangular
		drawContext.clearRect(0, 0, WIDTH, HEIGHT);
		drawContext.fillStyle = 'rgb(200, 200, 200)';
		drawContext.fillRect(0, 0, WIDTH, HEIGHT);

		// drawing line setting
		drawContext.lineWidth = 2;
		drawContext.strokeStyle = 'rgb(0, 0, 0)';
				
		// get samples 
		var dataArray = new Float32Array(analyser.frequencyBinCount);
		analyser.getFloatTimeDomainData(dataArray);
		
		
		
		var power=0;
    	var amp_envelop=80;

        power += dataArray[0];
        var amp_scale=100;
    	var sensitivity=0.1;
    	var current_level =     amp_scale*Math.log(1.0+1.0/sensitivity*power)/Math.log(1.0+1.0/sensitivity);

    	if(current_level>=amp_envelop*0.98){
      		if(current_level>=amp_envelop){
	   			amp_envelop=current_level;	
	   		}

	   		drawContext.beginPath();
			drawContext.arc(256, 256, amp_envelop, 0, 2*Math.PI, true);
			drawContext.stroke();
			current = new Date().getTime();
			time=current-start;
			if(time-peak[peak.length-1]>100){
				peak.push(time);
			}
		}
      	else{
      		drawContext.beginPath();
			drawContext.arc(256, 256, 0, 0, 2*Math.PI, true);
			drawContext.stroke();		
      	}
	    

      	for(var i=0;i<peak.length;i++){
      		console.log(peak[i]);
      	}

		// draw circle
		
		
				 
		// queue for next callback
		window.requestAnimationFrame(draw_wave);
	}

	function fileChanged(e){
		var file = e.target.files[0];
		var fileReader = new FileReader();
		fileReader.onload = fileLoaded;
		fileReader.readAsArrayBuffer(file);
	}

	function fileLoaded(e){
	    context.decodeAudioData(e.target.result, function(buffer) {
	      myAudioBuffer = buffer;
	    });
	}

	var source = null;
	function playSound(anybuffer) {
		source = context.createBufferSource();
	  	source.buffer = anybuffer;
	  	source.connect(context.destination);
	  	source.connect(analyser);
	  
	 	source.start();
	  	start = new Date().getTime();
	  	// visualize audio
	  	draw_wave();
	}

	function stopSound() {
	  	if (source) {
	   		source.stop();
	  	}
	}	   	
	</script>
</body>
</html>